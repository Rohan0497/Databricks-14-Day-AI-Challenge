# Day 4 Completed â€” Delta Lake Introduction (Databricks 14 Days AI Challenge)

Today I explored **Delta Lake basics** and practiced writing data in Delta format, creating Delta tables, and checking **schema enforcement**.

---

## ğŸ“Œ What I Learned Today
- What **Delta Lake** is and why itâ€™s used in Databricks
- How Delta supports **ACID transactions** on data lakes
- **Schema enforcement** (prevents accidental wrong writes)
- Delta vs Parquet (Delta adds transaction log + reliability features)
- How to deal with **duplicate inserts** using simple checks

---

## ğŸ› ï¸ Tasks I Completed
1. Converted CSV data into **Delta format**
2. Created Delta tables using **PySpark** and **SQL**
3. Tested **schema enforcement** by attempting a wrong append
4. Checked and handled **duplicate inserts**

---

## Screenshots

![Day 4 screenshot](../assets/day-04/ss1.png)
![Day 4 screenshot](../assets/day-04/ss2.png)
![Day 4 screenshot](../assets/day-04/ss3.png)

